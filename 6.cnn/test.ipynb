{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import random_split,DataLoader,Subset\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(1,5,4)\n",
    "torch.manual_seed(0)\n",
    "conv = nn.Conv2d(1,1,3,bias=False)\n",
    "torch.manual_seed(0)\n",
    "tconv = nn.ConvTranspose2d(1,1,3,bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight weight Parameter containing:\n",
      "tensor([[[[-0.0025,  0.1788, -0.2743],\n",
      "          [-0.2453, -0.1284,  0.0894],\n",
      "          [-0.0066,  0.2643, -0.0296]]]], requires_grad=True) Parameter containing:\n",
      "tensor([[[[-0.0025,  0.1788, -0.2743],\n",
      "          [-0.2453, -0.1284,  0.0894],\n",
      "          [-0.0066,  0.2643, -0.0296]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for (name1,param1),(name2,param2) in zip(conv.named_parameters(),tconv.named_parameters()):\n",
    "    param2 = -param1\n",
    "    print(name1,name2,param1,param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.1258, -1.1524, -0.2506, -0.4339],\n",
       "          [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
       "          [ 0.4681, -0.1577,  1.4437,  0.2660],\n",
       "          [ 1.3894,  1.5863,  0.9463, -0.8437],\n",
       "          [ 0.9318,  1.2590,  2.0050,  0.0537]]]),\n",
       " tensor([[[ 4.9849e-04, -3.8320e-02,  2.4126e-01, -2.8608e-01],\n",
       "          [ 4.8425e-02, -1.8786e-01, -2.9079e-01,  2.0948e-01],\n",
       "          [-5.3717e-02, -9.6137e-02,  5.4747e-01, -1.0152e-01],\n",
       "          [ 1.5009e-01,  1.1379e-01, -1.8942e-01,  2.3219e-02],\n",
       "          [ 4.0819e-03, -1.6414e-01,  4.9867e-02, -3.5351e-03]]],\n",
       "        grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = conv(x)\n",
    "x_ = tconv(y)\n",
    "x,x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"./data_for_test\"\n",
    "batch_size = 1000\n",
    "traindata = MNIST(ROOT, train=True,download=True,transform=T.ToTensor())\n",
    "traindata, valdata = random_split(traindata,[50000,10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift val data\n",
    "valdata.dataset.data[valdata.indices] = torch.roll(\n",
    "    valdata.dataset.data[valdata.indices],\n",
    "    shifts=(2, 2),\n",
    "    dims=(1, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(traindata,batch_size=batch_size,pin_memory=True,shuffle=True)\n",
    "evalloader = DataLoader(valdata,batch_size=batch_size,pin_memory=True,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainloader),len(evalloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "\n",
    "# setup training hyperparameters for the MLP\n",
    "num_epochs = 10\n",
    "learning_rate = 0.05\n",
    "momentum = 0.9\n",
    "linear_units = 30\n",
    "\n",
    "mlp_model = nn.Sequential(\n",
    "    nn.Linear(784, linear_units),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(linear_units, 10),\n",
    ").to(DEVICE)\n",
    "# create optimizer for the model\n",
    "optimizer_mlp = optim.SGD(mlp_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# setup training hyperparameters\n",
    "batch_size = 50\n",
    "learning_rate = 0.01\n",
    "# setup model hyperparameters\n",
    "kernel_size = (4, 4)\n",
    "stride = (2, 2)\n",
    "padding = (1, 1)\n",
    "n_filters_conv1 = 5\n",
    "n_filters_conv2 = 10\n",
    "\n",
    "conv_model = nn.Sequential(\n",
    "    nn.Conv2d(1, n_filters_conv1, kernel_size, stride, padding),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(n_filters_conv1, n_filters_conv2, kernel_size, stride, padding),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(490, 10),\n",
    ").to(DEVICE)\n",
    "optimizer_cnn = optim.SGD(conv_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy_score(y_hat, y):\n",
    "    if len(y_hat) != len(y):\n",
    "        raise ValueError(\"Lengths dont match\")\n",
    "    amax = y_hat.argmax(axis=1)\n",
    "    return (amax==y).sum()/len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optimizer,\n",
    "    num_epochs:int,\n",
    "    lossfun,\n",
    "    filename,\n",
    "    flatten = False,\n",
    "):\n",
    "    with open(filename,\"+a\") as f:\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"Epoch {} / {}:\".format(epoch + 1, num_epochs),file=f)\n",
    "            avgloss = 0\n",
    "            avgacc = 0\n",
    "            for X, y in loader:\n",
    "                X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "                if flatten:\n",
    "                    X = X.reshape(-1,784)\n",
    "                y_hat = model(X)\n",
    "                loss = lossfun(y_hat, y)\n",
    "                acc = accuracy_score(y_hat, y)\n",
    "                avgloss += loss.item()\n",
    "                avgacc += acc\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            print(\"  Training Accuracy: {:.4f}\".format(avgacc/len(loader)),file=f)\n",
    "            print(\"  Training Cost: {:.4f}\".format(avgloss/len(loader)),file=f)\n",
    "def eval(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    lossfun,\n",
    "    filename,\n",
    "    flatten = False,\n",
    "):\n",
    "    with open(filename,\"+a\") as f:\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            avgloss = 0\n",
    "            avgacc = 0\n",
    "            for X, y in loader:\n",
    "                X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "                if flatten:\n",
    "                    X = X.reshape(-1,784)\n",
    "                y_hat = model(X)\n",
    "                loss = lossfun(y_hat, y)\n",
    "                acc = accuracy_score(y_hat, y)\n",
    "                avgloss += loss.item()\n",
    "                avgacc += acc\n",
    "\n",
    "            print(\"  Training Accuracy: {:.4f}\".format(avgacc/len(loader)),file=f)\n",
    "            print(\"  Training Cost: {:.4f}\".format(avgloss/len(loader)),file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"result_shifted.txt\"\n",
    "with open(FILENAME,\"+a\") as f:\n",
    "    print(\"MLP\",file=f)\n",
    "train(\n",
    "    mlp_model,\n",
    "    trainloader,\n",
    "    optimizer_mlp,\n",
    "    num_epochs,\n",
    "    lossfun,\n",
    "    FILENAME,\n",
    "    flatten=True,\n",
    ")\n",
    "eval(\n",
    "    mlp_model,\n",
    "    evalloader,\n",
    "    lossfun,\n",
    "    FILENAME,\n",
    "    flatten=True,\n",
    ")\n",
    "with open(FILENAME,\"+a\") as f:\n",
    "    print(\"CNN\",file=f)\n",
    "train(\n",
    "    conv_model,\n",
    "    trainloader,\n",
    "    optimizer_cnn,\n",
    "    num_epochs,\n",
    "    lossfun,\n",
    "    FILENAME,\n",
    ")\n",
    "eval(\n",
    "    conv_model,\n",
    "    evalloader,\n",
    "    lossfun,\n",
    "    FILENAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(1,5)\n",
    "w = np.array([2,1,3])\n",
    "y=np.array([2,4])\n",
    "b=1\n",
    "x,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=np.correlate(x,w,mode=\"valid\")+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".5*(y-y_hat)@(y-y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw=np.correlate(y_hat-y,x,mode=\"valid\")[::-1]\n",
    "lw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = (y_hat-y).sum()\n",
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new = w-0.01*lw\n",
    "b_new = b-0.01*lb\n",
    "w_new, b_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_new=np.correlate(x,w_new,mode=\"valid\")+b_new\n",
    "y_hat_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".5*(y-y_hat_new)@(y-y_hat_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
